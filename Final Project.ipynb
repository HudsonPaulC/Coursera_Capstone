{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing New York to Toronto to determine how similiar or dissimilar  they are\n",
    "Using the neighborhood data for NY and TO, I will build K amount\n",
    "of clusters based on their top ten venues. If it turns out that most clusters do\n",
    "not include TO and NY neighborhoods, we can say TO and NY are dissimilar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3>\n",
    "\n",
    "1. <a href=\"#item1\">Download and Explore Dataset</a>\n",
    "\n",
    "2. <a href=\"#item2\">Explore Neighborhoods in New York City</a>\n",
    "\n",
    "3. <a href=\"#item3\">Analyze Each Neighborhood</a>\n",
    "\n",
    "4. <a href=\"#item4\">Cluster Neighborhoods</a>\n",
    "\n",
    "5. <a href=\"#item5\">Examine Clusters</a>    \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Toronto City into Dataframe TO_neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd # library for data analsysis\n",
    "import requests # library to handle requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = requests.get(\"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\")\n",
    "htmltext = url.text\n",
    "print('XML Downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "\n",
    "soup = bs4.BeautifulSoup(htmltext, 'lxml')\n",
    "table = soup.find('table','wikitable sortable')\n",
    "#print (table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "            n_columns = 0\n",
    "            n_rows=0\n",
    "            column_names = []\n",
    "    \n",
    "            # Find number of rows and columns\n",
    "            # we also find the column titles if we can\n",
    "            for row in table.find_all('tr'):\n",
    "                \n",
    "                # Determine the number of rows in the table\n",
    "                td_tags = row.find_all('td')\n",
    "                if len(td_tags) > 0:\n",
    "                    n_rows+=1\n",
    "                    if n_columns == 0:\n",
    "                        # Set the number of columns for our table\n",
    "                        n_columns = len(td_tags)\n",
    "                        \n",
    "                # Handle column names if we find them\n",
    "                th_tags = row.find_all('th') \n",
    "                if len(th_tags) > 0 and len(column_names) == 0:\n",
    "                    for th in th_tags:\n",
    "                        column_names.append(th.get_text().replace('\\n', ''))\n",
    "    \n",
    "            # Safeguard on Column Titles\n",
    "            if len(column_names) > 0 and len(column_names) != n_columns:\n",
    "                raise Exception(\"Column titles do not match the number of columns\")\n",
    "            print (column_names)\n",
    "            columns = column_names if len(column_names) > 0 else range(0,n_columns)\n",
    "            df = pd.DataFrame(columns = columns,\n",
    "                              index= range(0,n_rows))\n",
    "            row_marker = 0\n",
    "            for row in table.find_all('tr'):\n",
    "                column_marker = 0\n",
    "                columns = row.find_all('td')\n",
    "                for column in columns:\n",
    "                    df.iat[row_marker,column_marker] = column.get_text()\n",
    "                    column_marker += 1\n",
    "                if len(columns) > 0:\n",
    "                    row_marker += 1\n",
    "                    \n",
    "df = df.replace('\\n','', regex=True)\n",
    "df = df[df.Borough != \"Not assigned\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget -O Geospatial_data.csv http://cocl.us/Geospatial_data/Geospatial_Coordinates.csv\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Geospatial_data_df = pd.read_csv(\"Geospatial_data.csv\")\n",
    "\n",
    "Geospatial_data_df.rename(columns={'Postal Code': 'Postcode'}, inplace=True)\n",
    "TO_neighborhoods = pd.merge(df, Geospatial_data_df, on='Postcode')\n",
    "\n",
    "TO_neighborhoods.rename(columns={'Postcode': 'City'}, inplace=True)\n",
    "TO_neighborhoods.rename(columns={'Neighbourhood': 'Neighborhood'}, inplace=True)\n",
    "TO_neighborhoods['City'] = 'TO'\n",
    "TO_neighborhoods.head()\n",
    "\n",
    "downtown_toronto_data = TO_neighborhoods[TO_neighborhoods['Borough'] == 'Downtown Toronto'].reset_index(drop=True)\n",
    "downtown_toronto_data['Borough'] = 'TO_' + downtown_toronto_data['Borough']\n",
    "downtown_toronto_data['Neighborhood'] = 'TO_' + downtown_toronto_data['Neighborhood'] \n",
    "downtown_toronto_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download New York City into Dataframe NY_neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json # library to handle JSON files\n",
    "from pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget -q -O 'newyork_data.json' https://cocl.us/new_york_dataset\n",
    "\n",
    "with open('newyork_data.json') as NY_json_data:\n",
    "    NY_data = json.load(NY_json_data)\n",
    "    \n",
    "# Notice how all the relevant data is in the features key, which is basically a list of the neighborhoods. \n",
    "# So, let's define a new variable that includes this data   \n",
    "\n",
    "NY_features_data = NY_data['features']\n",
    "\n",
    "# Tranform the JSON data into a pandas dataframe\n",
    "# define the dataframe columns\n",
    "column_names = ['City', 'Borough', 'Neighborhood', 'Latitude', 'Longitude'] \n",
    "\n",
    "# instantiate the dataframe\n",
    "NY_neighborhoods = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for data in NY_features_data:\n",
    "    city = 'NY'\n",
    "    borough = neighborhood_name = data['properties']['borough'] \n",
    "    neighborhood_name = data['properties']['name']\n",
    "        \n",
    "    neighborhood_latlon = data['geometry']['coordinates']\n",
    "    neighborhood_lat = neighborhood_latlon[1]\n",
    "    neighborhood_lon = neighborhood_latlon[0]\n",
    "    \n",
    "    NY_neighborhoods = NY_neighborhoods.append({'City': city,\n",
    "                                          'Borough': borough,\n",
    "                                          'Neighborhood': neighborhood_name,\n",
    "                                          'Latitude': neighborhood_lat,\n",
    "                                          'Longitude': neighborhood_lon}, ignore_index=True)\n",
    "\n",
    "print (\"NY Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NY_neighborhoods.head()\n",
    "NY_neighborhoods.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manhattan_data = NY_neighborhoods[NY_neighborhoods['Borough'] == 'Manhattan'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manhattan_data['Borough'] = 'NY_' + manhattan_data['Borough'] \n",
    "manhattan_data['Neighborhood'] = 'NY_' + manhattan_data['Neighborhood'] \n",
    "manhattan_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Concatenate the NY neighborhoods with Toronto neighborhoods into neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TO_neighborhoods.reset_index()\n",
    "neighborhood_data = pd.concat([manhattan_data, downtown_toronto_data], axis=0).reset_index()\n",
    "neighborhood_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neighborhood_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neighborhood_data.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Next, we are going to start utilizing the Foursquare API to explore the neighborhoods and segment them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Foursquare Credentials and Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CLIENT_ID = 'JVFWKWHDS0TWEDRK4F44GHOHWOS1DOHFZLRI14J1BKB5YO12' # your Foursquare ID\n",
    "CLIENT_SECRET = 'HFR4PME5VUMUESCRPCDIGP2OBHC2HI4TF4ZYHEFZM3NA0FHP' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to clean the json and structure it into a *pandas* dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Explore the neighborhoods or NY and TO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Neighborhood', \n",
    "                  'Neighborhood Latitude', \n",
    "                  'Neighborhood Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now write the code to run the above function on each neighborhood and create a new dataframe called *manhattan_venues*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LIMIT = 100 # limit of number of venues returned by Foursquare API\n",
    "\n",
    "radius = 500 # define radius\n",
    "\n",
    "neighborhood_venues = getNearbyVenues(names=neighborhood_data['Neighborhood'],\n",
    "                                   latitudes=neighborhood_data['Latitude'],\n",
    "                                   longitudes=neighborhood_data['Longitude']\n",
    "                                  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check the size of the resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(neighborhood_venues.shape)\n",
    "neighborhood_venues.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many venues were returned for each neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighborhood_venues.groupby('Neighborhood').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's find out how many unique categories can be curated from all the returned venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('There are {} uniques categories.'.format(len(neighborhood_venues['Venue Category'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Each Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "neighborhood_onehot = pd.get_dummies(neighborhood_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "neighborhood_onehot['Neighborhood'] = neighborhood_venues['Neighborhood'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [neighborhood_onehot.columns[-1]] + list(neighborhood_onehot.columns[:-1])\n",
    "neighborhood_onehot = neighborhood_onehot[fixed_columns]\n",
    "\n",
    "neighborhood_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's examine the new dataframe size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighborhood_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, let's group rows by neighborhood and by taking the mean of the frequency of occurrence of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighborhood_grouped = neighborhood_onehot.groupby('Neighborhood').mean().reset_index()\n",
    "neighborhood_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's confirm the new size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighborhood_grouped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's print each neighborhood along with the top 5 most common venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_top_venues = 5\n",
    "\n",
    "for hood in neighborhood_grouped['Neighborhood']:\n",
    "    print(\"----\"+hood+\"----\")\n",
    "    temp = neighborhood_grouped[neighborhood_grouped['Neighborhood'] == hood].T.reset_index()\n",
    "    temp.columns = ['venue','freq']\n",
    "    temp = temp.iloc[1:]\n",
    "    temp['freq'] = temp['freq'].astype(float)\n",
    "    temp = temp.round({'freq': 2})\n",
    "    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's put that into a *pandas* dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's write a function to sort the venues in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # library to handle data in a vectorized manner\n",
    "\n",
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the new dataframe and display the top 10 venues for each neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Neighborhood']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "neighborhoods_venues_sorted = pd.DataFrame(columns=columns)\n",
    "neighborhoods_venues_sorted['Neighborhood'] = neighborhood_grouped['Neighborhood']\n",
    "\n",
    "for ind in np.arange(neighborhood_grouped.shape[0]):\n",
    "    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(neighborhood_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "neighborhoods_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cluster Neighborhoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run *k*-means to cluster the neighborhood into 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# set number of clusters\n",
    "kclusters = 8\n",
    "\n",
    "neighborhood_grouped_clustering = neighborhood_grouped.drop('Neighborhood', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(neighborhood_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new dataframe that includes the cluster as well as the top 10 venues for each neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add clustering labels\n",
    "neighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "\n",
    "neighborhood_merged = neighborhood_data\n",
    "\n",
    "# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\n",
    "neighborhood_merged = neighborhood_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n",
    "\n",
    "neighborhood_merged.head() # check the last columns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's visualize the resulting clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='item5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Examine Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can examine each cluster and determine the discriminating venue categories that distinguish each cluster. Based on the defining categories, you can then assign a name to each cluster. I will leave this exercise to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighborhood_merged.loc[neighborhood_merged['Cluster Labels'] == 0, neighborhood_merged.columns[[3] + list(range(5, neighborhood_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_merged.loc[neighborhood_merged['Cluster Labels'] == 1, neighborhood_merged.columns[[1] + list(range(5, neighborhood_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_merged.loc[neighborhood_merged['Cluster Labels'] == 2, neighborhood_merged.columns[[1] + list(range(5, neighborhood_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighborhood_merged.loc[neighborhood_merged['Cluster Labels'] == 3, neighborhood_merged.columns[[1] + list(range(5, neighborhood_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighborhood_merged.loc[neighborhood_merged['Cluster Labels'] == 4, neighborhood_merged.columns[[1] + list(range(5, neighborhood_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighborhood_merged.loc[neighborhood_merged['Cluster Labels'] == 5, neighborhood_merged.columns[[1] + list(range(5, neighborhood_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighborhood_merged.loc[neighborhood_merged['Cluster Labels'] == 6, neighborhood_merged.columns[[1] + list(range(5, neighborhood_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neighborhood_merged.loc[neighborhood_merged['Cluster Labels'] == 7, neighborhood_merged.columns[[1] + list(range(5, neighborhood_merged.shape[1]))]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
